{"id":"../node_modules/react-speech-recognition/lib/SpeechRecognition.js","dependencies":[{"name":"/parcel_blueprint/package.json","includedInParent":true,"mtime":1718649238098},{"name":"/parcel_blueprint/.babelrc","includedInParent":true,"mtime":1718293933214},{"name":"/parcel_blueprint/node_modules/react-speech-recognition/package.json","includedInParent":true,"mtime":1718647516657},{"name":"react","loc":{"line":8,"column":21,"index":162},"parent":"/parcel_blueprint/node_modules/react-speech-recognition/lib/SpeechRecognition.js","resolved":"/parcel_blueprint/node_modules/react/index.js"},{"name":"./utils","loc":{"line":10,"column":21,"index":194},"parent":"/parcel_blueprint/node_modules/react-speech-recognition/lib/SpeechRecognition.js","resolved":"/parcel_blueprint/node_modules/react-speech-recognition/lib/utils.js"},{"name":"./actions","loc":{"line":12,"column":23,"index":230},"parent":"/parcel_blueprint/node_modules/react-speech-recognition/lib/SpeechRecognition.js","resolved":"/parcel_blueprint/node_modules/react-speech-recognition/lib/actions.js"},{"name":"./reducers","loc":{"line":14,"column":24,"index":269},"parent":"/parcel_blueprint/node_modules/react-speech-recognition/lib/SpeechRecognition.js","resolved":"/parcel_blueprint/node_modules/react-speech-recognition/lib/reducers.js"},{"name":"./RecognitionManager","loc":{"line":16,"column":57,"index":342},"parent":"/parcel_blueprint/node_modules/react-speech-recognition/lib/SpeechRecognition.js","resolved":"/parcel_blueprint/node_modules/react-speech-recognition/lib/RecognitionManager.js"},{"name":"./isAndroid","loc":{"line":18,"column":48,"index":417},"parent":"/parcel_blueprint/node_modules/react-speech-recognition/lib/SpeechRecognition.js","resolved":"/parcel_blueprint/node_modules/react-speech-recognition/lib/isAndroid.js"},{"name":"./NativeSpeechRecognition","loc":{"line":20,"column":62,"index":497},"parent":"/parcel_blueprint/node_modules/react-speech-recognition/lib/SpeechRecognition.js","resolved":"/parcel_blueprint/node_modules/react-speech-recognition/lib/NativeSpeechRecognition.js"}],"generated":{"js":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports[\"default\"] = exports.useSpeechRecognition = void 0;\n\nvar _react = require(\"react\");\n\nvar _utils = require(\"./utils\");\n\nvar _actions = require(\"./actions\");\n\nvar _reducers = require(\"./reducers\");\n\nvar _RecognitionManager = _interopRequireDefault(require(\"./RecognitionManager\"));\n\nvar _isAndroid = _interopRequireDefault(require(\"./isAndroid\"));\n\nvar _NativeSpeechRecognition = _interopRequireDefault(require(\"./NativeSpeechRecognition\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { \"default\": obj }; }\n\nfunction asyncGeneratorStep(gen, resolve, reject, _next, _throw, key, arg) { try { var info = gen[key](arg); var value = info.value; } catch (error) { reject(error); return; } if (info.done) { resolve(value); } else { Promise.resolve(value).then(_next, _throw); } }\n\nfunction _asyncToGenerator(fn) { return function () { var self = this, args = arguments; return new Promise(function (resolve, reject) { var gen = fn.apply(self, args); function _next(value) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, \"next\", value); } function _throw(err) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, \"throw\", err); } _next(undefined); }); }; }\n\nfunction _toConsumableArray(arr) { return _arrayWithoutHoles(arr) || _iterableToArray(arr) || _unsupportedIterableToArray(arr) || _nonIterableSpread(); }\n\nfunction _nonIterableSpread() { throw new TypeError(\"Invalid attempt to spread non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); }\n\nfunction _iterableToArray(iter) { if (typeof Symbol !== \"undefined\" && Symbol.iterator in Object(iter)) return Array.from(iter); }\n\nfunction _arrayWithoutHoles(arr) { if (Array.isArray(arr)) return _arrayLikeToArray(arr); }\n\nfunction _typeof(obj) { \"@babel/helpers - typeof\"; if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { _typeof = function _typeof(obj) { return typeof obj; }; } else { _typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return _typeof(obj); }\n\nfunction _slicedToArray(arr, i) { return _arrayWithHoles(arr) || _iterableToArrayLimit(arr, i) || _unsupportedIterableToArray(arr, i) || _nonIterableRest(); }\n\nfunction _nonIterableRest() { throw new TypeError(\"Invalid attempt to destructure non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); }\n\nfunction _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === \"string\") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === \"Object\" && o.constructor) n = o.constructor.name; if (n === \"Map\" || n === \"Set\") return Array.from(o); if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }\n\nfunction _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) { arr2[i] = arr[i]; } return arr2; }\n\nfunction _iterableToArrayLimit(arr, i) { if (typeof Symbol === \"undefined\" || !(Symbol.iterator in Object(arr))) return; var _arr = []; var _n = true; var _d = false; var _e = undefined; try { for (var _i = arr[Symbol.iterator](), _s; !(_n = (_s = _i.next()).done); _n = true) { _arr.push(_s.value); if (i && _arr.length === i) break; } } catch (err) { _d = true; _e = err; } finally { try { if (!_n && _i[\"return\"] != null) _i[\"return\"](); } finally { if (_d) throw _e; } } return _arr; }\n\nfunction _arrayWithHoles(arr) { if (Array.isArray(arr)) return arr; }\n\nvar _browserSupportsSpeechRecognition = !!_NativeSpeechRecognition[\"default\"];\n\nvar _browserSupportsContinuousListening = _browserSupportsSpeechRecognition && !(0, _isAndroid[\"default\"])();\n\nvar recognitionManager;\n\nvar useSpeechRecognition = function useSpeechRecognition() {\n  var _ref = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {},\n      _ref$transcribing = _ref.transcribing,\n      transcribing = _ref$transcribing === void 0 ? true : _ref$transcribing,\n      _ref$clearTranscriptO = _ref.clearTranscriptOnListen,\n      clearTranscriptOnListen = _ref$clearTranscriptO === void 0 ? true : _ref$clearTranscriptO,\n      _ref$commands = _ref.commands,\n      commands = _ref$commands === void 0 ? [] : _ref$commands;\n\n  var _useState = (0, _react.useState)(SpeechRecognition.getRecognitionManager()),\n      _useState2 = _slicedToArray(_useState, 1),\n      recognitionManager = _useState2[0];\n\n  var _useState3 = (0, _react.useState)(_browserSupportsSpeechRecognition),\n      _useState4 = _slicedToArray(_useState3, 2),\n      browserSupportsSpeechRecognition = _useState4[0],\n      setBrowserSupportsSpeechRecognition = _useState4[1];\n\n  var _useState5 = (0, _react.useState)(_browserSupportsContinuousListening),\n      _useState6 = _slicedToArray(_useState5, 2),\n      browserSupportsContinuousListening = _useState6[0],\n      setBrowserSupportsContinuousListening = _useState6[1];\n\n  var _useReducer = (0, _react.useReducer)(_reducers.transcriptReducer, {\n    interimTranscript: recognitionManager.interimTranscript,\n    finalTranscript: ''\n  }),\n      _useReducer2 = _slicedToArray(_useReducer, 2),\n      _useReducer2$ = _useReducer2[0],\n      interimTranscript = _useReducer2$.interimTranscript,\n      finalTranscript = _useReducer2$.finalTranscript,\n      dispatch = _useReducer2[1];\n\n  var _useState7 = (0, _react.useState)(recognitionManager.listening),\n      _useState8 = _slicedToArray(_useState7, 2),\n      listening = _useState8[0],\n      setListening = _useState8[1];\n\n  var _useState9 = (0, _react.useState)(recognitionManager.isMicrophoneAvailable),\n      _useState10 = _slicedToArray(_useState9, 2),\n      isMicrophoneAvailable = _useState10[0],\n      setMicrophoneAvailable = _useState10[1];\n\n  var commandsRef = (0, _react.useRef)(commands);\n  commandsRef.current = commands;\n\n  var dispatchClearTranscript = function dispatchClearTranscript() {\n    dispatch((0, _actions.clearTranscript)());\n  };\n\n  var resetTranscript = (0, _react.useCallback)(function () {\n    recognitionManager.resetTranscript();\n    dispatchClearTranscript();\n  }, [recognitionManager]);\n\n  var testFuzzyMatch = function testFuzzyMatch(command, input, fuzzyMatchingThreshold) {\n    var commandToString = _typeof(command) === 'object' ? command.toString() : command;\n    var commandWithoutSpecials = commandToString.replace(/[&/\\\\#,+()!$~%.'\":*?<>{}]/g, '').replace(/  +/g, ' ').trim();\n    var howSimilar = (0, _utils.compareTwoStringsUsingDiceCoefficient)(commandWithoutSpecials, input);\n\n    if (howSimilar >= fuzzyMatchingThreshold) {\n      return {\n        command: command,\n        commandWithoutSpecials: commandWithoutSpecials,\n        howSimilar: howSimilar,\n        isFuzzyMatch: true\n      };\n    }\n\n    return null;\n  };\n\n  var testMatch = function testMatch(command, input) {\n    var pattern = (0, _utils.commandToRegExp)(command);\n    var result = pattern.exec(input);\n\n    if (result) {\n      return {\n        command: command,\n        parameters: result.slice(1)\n      };\n    }\n\n    return null;\n  };\n\n  var matchCommands = (0, _react.useCallback)(function (newInterimTranscript, newFinalTranscript) {\n    commandsRef.current.forEach(function (_ref2) {\n      var command = _ref2.command,\n          callback = _ref2.callback,\n          _ref2$matchInterim = _ref2.matchInterim,\n          matchInterim = _ref2$matchInterim === void 0 ? false : _ref2$matchInterim,\n          _ref2$isFuzzyMatch = _ref2.isFuzzyMatch,\n          isFuzzyMatch = _ref2$isFuzzyMatch === void 0 ? false : _ref2$isFuzzyMatch,\n          _ref2$fuzzyMatchingTh = _ref2.fuzzyMatchingThreshold,\n          fuzzyMatchingThreshold = _ref2$fuzzyMatchingTh === void 0 ? 0.8 : _ref2$fuzzyMatchingTh,\n          _ref2$bestMatchOnly = _ref2.bestMatchOnly,\n          bestMatchOnly = _ref2$bestMatchOnly === void 0 ? false : _ref2$bestMatchOnly;\n      var input = !newFinalTranscript && matchInterim ? newInterimTranscript.trim() : newFinalTranscript.trim();\n      var subcommands = Array.isArray(command) ? command : [command];\n      var results = subcommands.map(function (subcommand) {\n        if (isFuzzyMatch) {\n          return testFuzzyMatch(subcommand, input, fuzzyMatchingThreshold);\n        }\n\n        return testMatch(subcommand, input);\n      }).filter(function (x) {\n        return x;\n      });\n\n      if (isFuzzyMatch && bestMatchOnly && results.length >= 2) {\n        results.sort(function (a, b) {\n          return b.howSimilar - a.howSimilar;\n        });\n        var _results$ = results[0],\n            _command = _results$.command,\n            commandWithoutSpecials = _results$.commandWithoutSpecials,\n            howSimilar = _results$.howSimilar;\n        callback(commandWithoutSpecials, input, howSimilar, {\n          command: _command,\n          resetTranscript: resetTranscript\n        });\n      } else {\n        results.forEach(function (result) {\n          if (result.isFuzzyMatch) {\n            var _command2 = result.command,\n                _commandWithoutSpecials = result.commandWithoutSpecials,\n                _howSimilar = result.howSimilar;\n            callback(_commandWithoutSpecials, input, _howSimilar, {\n              command: _command2,\n              resetTranscript: resetTranscript\n            });\n          } else {\n            var _command3 = result.command,\n                parameters = result.parameters;\n            callback.apply(void 0, _toConsumableArray(parameters).concat([{\n              command: _command3,\n              resetTranscript: resetTranscript\n            }]));\n          }\n        });\n      }\n    });\n  }, [resetTranscript]);\n  var handleTranscriptChange = (0, _react.useCallback)(function (newInterimTranscript, newFinalTranscript) {\n    if (transcribing) {\n      dispatch((0, _actions.appendTranscript)(newInterimTranscript, newFinalTranscript));\n    }\n\n    matchCommands(newInterimTranscript, newFinalTranscript);\n  }, [matchCommands, transcribing]);\n  var handleClearTranscript = (0, _react.useCallback)(function () {\n    if (clearTranscriptOnListen) {\n      dispatchClearTranscript();\n    }\n  }, [clearTranscriptOnListen]);\n  (0, _react.useEffect)(function () {\n    var id = SpeechRecognition.counter;\n    SpeechRecognition.counter += 1;\n    var callbacks = {\n      onListeningChange: setListening,\n      onMicrophoneAvailabilityChange: setMicrophoneAvailable,\n      onTranscriptChange: handleTranscriptChange,\n      onClearTranscript: handleClearTranscript,\n      onBrowserSupportsSpeechRecognitionChange: setBrowserSupportsSpeechRecognition,\n      onBrowserSupportsContinuousListeningChange: setBrowserSupportsContinuousListening\n    };\n    recognitionManager.subscribe(id, callbacks);\n    return function () {\n      recognitionManager.unsubscribe(id);\n    };\n  }, [transcribing, clearTranscriptOnListen, recognitionManager, handleTranscriptChange, handleClearTranscript]);\n  var transcript = (0, _utils.concatTranscripts)(finalTranscript, interimTranscript);\n  return {\n    transcript: transcript,\n    interimTranscript: interimTranscript,\n    finalTranscript: finalTranscript,\n    listening: listening,\n    isMicrophoneAvailable: isMicrophoneAvailable,\n    resetTranscript: resetTranscript,\n    browserSupportsSpeechRecognition: browserSupportsSpeechRecognition,\n    browserSupportsContinuousListening: browserSupportsContinuousListening\n  };\n};\n\nexports.useSpeechRecognition = useSpeechRecognition;\nvar SpeechRecognition = {\n  counter: 0,\n  applyPolyfill: function applyPolyfill(PolyfillSpeechRecognition) {\n    if (recognitionManager) {\n      recognitionManager.setSpeechRecognition(PolyfillSpeechRecognition);\n    } else {\n      recognitionManager = new _RecognitionManager[\"default\"](PolyfillSpeechRecognition);\n    }\n\n    var browserSupportsPolyfill = !!PolyfillSpeechRecognition && (0, _utils.browserSupportsPolyfills)();\n    _browserSupportsSpeechRecognition = browserSupportsPolyfill;\n    _browserSupportsContinuousListening = browserSupportsPolyfill;\n  },\n  removePolyfill: function removePolyfill() {\n    if (recognitionManager) {\n      recognitionManager.setSpeechRecognition(_NativeSpeechRecognition[\"default\"]);\n    } else {\n      recognitionManager = new _RecognitionManager[\"default\"](_NativeSpeechRecognition[\"default\"]);\n    }\n\n    _browserSupportsSpeechRecognition = !!_NativeSpeechRecognition[\"default\"];\n    _browserSupportsContinuousListening = _browserSupportsSpeechRecognition && !(0, _isAndroid[\"default\"])();\n  },\n  getRecognitionManager: function getRecognitionManager() {\n    if (!recognitionManager) {\n      recognitionManager = new _RecognitionManager[\"default\"](_NativeSpeechRecognition[\"default\"]);\n    }\n\n    return recognitionManager;\n  },\n  getRecognition: function getRecognition() {\n    var recognitionManager = SpeechRecognition.getRecognitionManager();\n    return recognitionManager.getRecognition();\n  },\n  startListening: function () {\n    var _startListening = _asyncToGenerator( /*#__PURE__*/regeneratorRuntime.mark(function _callee() {\n      var _ref3,\n          continuous,\n          language,\n          recognitionManager,\n          _args = arguments;\n\n      return regeneratorRuntime.wrap(function _callee$(_context) {\n        while (1) {\n          switch (_context.prev = _context.next) {\n            case 0:\n              _ref3 = _args.length > 0 && _args[0] !== undefined ? _args[0] : {}, continuous = _ref3.continuous, language = _ref3.language;\n              recognitionManager = SpeechRecognition.getRecognitionManager();\n              _context.next = 4;\n              return recognitionManager.startListening({\n                continuous: continuous,\n                language: language\n              });\n\n            case 4:\n            case \"end\":\n              return _context.stop();\n          }\n        }\n      }, _callee);\n    }));\n\n    function startListening() {\n      return _startListening.apply(this, arguments);\n    }\n\n    return startListening;\n  }(),\n  stopListening: function () {\n    var _stopListening = _asyncToGenerator( /*#__PURE__*/regeneratorRuntime.mark(function _callee2() {\n      var recognitionManager;\n      return regeneratorRuntime.wrap(function _callee2$(_context2) {\n        while (1) {\n          switch (_context2.prev = _context2.next) {\n            case 0:\n              recognitionManager = SpeechRecognition.getRecognitionManager();\n              _context2.next = 3;\n              return recognitionManager.stopListening();\n\n            case 3:\n            case \"end\":\n              return _context2.stop();\n          }\n        }\n      }, _callee2);\n    }));\n\n    function stopListening() {\n      return _stopListening.apply(this, arguments);\n    }\n\n    return stopListening;\n  }(),\n  abortListening: function () {\n    var _abortListening = _asyncToGenerator( /*#__PURE__*/regeneratorRuntime.mark(function _callee3() {\n      var recognitionManager;\n      return regeneratorRuntime.wrap(function _callee3$(_context3) {\n        while (1) {\n          switch (_context3.prev = _context3.next) {\n            case 0:\n              recognitionManager = SpeechRecognition.getRecognitionManager();\n              _context3.next = 3;\n              return recognitionManager.abortListening();\n\n            case 3:\n            case \"end\":\n              return _context3.stop();\n          }\n        }\n      }, _callee3);\n    }));\n\n    function abortListening() {\n      return _abortListening.apply(this, arguments);\n    }\n\n    return abortListening;\n  }(),\n  browserSupportsSpeechRecognition: function browserSupportsSpeechRecognition() {\n    return _browserSupportsSpeechRecognition;\n  },\n  browserSupportsContinuousListening: function browserSupportsContinuousListening() {\n    return _browserSupportsContinuousListening;\n  }\n};\nvar _default = SpeechRecognition;\nexports[\"default\"] = _default;"},"sourceMaps":null,"error":null,"hash":"ce2469701f4c652f6d5c5d88766ee0c1","cacheData":{"env":{}}}